{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-09-18T03:40:55.582024Z","iopub.status.busy":"2021-09-18T03:40:55.581243Z","iopub.status.idle":"2021-09-18T03:41:00.071535Z","shell.execute_reply":"2021-09-18T03:41:00.070216Z","shell.execute_reply.started":"2021-09-18T03:40:55.581923Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["import torch\n","import torch.nn as nn\n","import time\n","import argparse\n","\n","import os\n","import datetime\n","\n","from torch.distributions.categorical import Categorical\n","\n","# visualization \n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","\n","device = torch.device(\"cpu\"); gpu_id = -1 # select CPU\n","\n","gpu_id = '0' # select a single GPU  \n","#gpu_id = '2,3' # select multiple GPUs  \n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))   \n","    \n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["# Model's Components"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-09-18T03:41:00.078766Z","iopub.status.busy":"2021-09-18T03:41:00.07652Z","iopub.status.idle":"2021-09-18T03:41:00.175142Z","shell.execute_reply":"2021-09-18T03:41:00.17259Z","shell.execute_reply.started":"2021-09-18T03:41:00.078722Z"},"trusted":true},"outputs":[],"source":["import math\n","import numpy as np\n","import torch.nn.functional as F\n","import random\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.optim import lr_scheduler\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm_notebook\n","\n","class TransEncoderNet(nn.Module):\n","    \"\"\"\n","    Encoder network based on self-attention transformer\n","    Inputs :  \n","      h of size      (bsz, nb_nodes, dim_emb)    batch of input cities\n","    Outputs :  \n","      h of size      (bsz, nb_nodes, dim_emb)    batch of encoded cities\n","      score of size  (bsz, nb_nodes, nb_nodes+1) batch of attention scores\n","    \"\"\"\n","    \n","    def __init__(self, nb_layers, dim_emb, nb_heads, dim_ff, batchnorm):\n","        super(TransEncoderNet, self).__init__()\n","        assert dim_emb == nb_heads* (dim_emb//nb_heads) # check if dim_emb is divisible by nb_heads\n","        self.MHA_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n","        self.linear1_layers = nn.ModuleList( [nn.Linear(dim_emb, dim_ff) for _ in range(nb_layers)] )\n","        self.linear2_layers = nn.ModuleList( [nn.Linear(dim_ff, dim_emb) for _ in range(nb_layers)] )   \n","        if batchnorm:\n","            self.norm1_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n","            self.norm2_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n","        else:\n","            self.norm1_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n","            self.norm2_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n","        self.nb_layers = nb_layers\n","        self.nb_heads = nb_heads\n","        self.batchnorm = batchnorm\n","        \n","    def forward(self, h):      \n","        # PyTorch nn.MultiheadAttention requires input size (seq_len, bsz, dim_emb) \n","        h = h.transpose(0,1) # size(h)=(nb_nodes, bsz, dim_emb)  \n","        # L layers\n","        for i in range(self.nb_layers):\n","            h_rc = h # residual connection, size(h_rc)=(nb_nodes, bsz, dim_emb)\n","            h, score = self.MHA_layers[i](h, h, h) # size(h)=(nb_nodes, bsz, dim_emb), size(score)=(bsz, nb_nodes, nb_nodes)\n","            # add residual connection\n","            \n","            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n","            if self.batchnorm:\n","                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n","                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n","                h = self.norm1_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n","                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n","            else:\n","                h = self.norm1_layers[i](h)       # size(h)=(nb_nodes, bsz, dim_emb) \n","            # feedforward\n","            h_rc = h # residual connection\n","            h = self.linear2_layers[i](torch.relu(self.linear1_layers[i](h)))\n","            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n","            if self.batchnorm:\n","                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n","                h = self.norm2_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n","                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n","            else:\n","                h = self.norm2_layers[i](h) # size(h)=(nb_nodes, bsz, dim_emb)\n","        # Transpose h\n","        h = h.transpose(0,1) # size(h)=(bsz, nb_nodes, dim_emb)\n","        return h, score\n","    \n","\n","class Attention(nn.Module):\n","    def __init__(self, n_hidden):\n","        super(Attention, self).__init__()\n","        self.size = 0\n","        self.batch_size = 0\n","        self.dim = n_hidden\n","        \n","        v  = torch.FloatTensor(n_hidden)\n","        self.v  = nn.Parameter(v)\n","        self.v.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n","        \n","        # parameters for pointer attention\n","        self.Wref = nn.Linear(n_hidden, n_hidden)\n","        self.Wq = nn.Linear(n_hidden, n_hidden)\n","    \n","    \n","    def forward(self, q, ref):       # query and reference\n","        self.batch_size = q.size(0)\n","        self.size = int(ref.size(0) / self.batch_size)\n","        q = self.Wq(q)     # (B, dim)\n","        ref = self.Wref(ref)\n","        ref = ref.view(self.batch_size, self.size, self.dim)  # (B, size, dim)\n","        \n","        q_ex = q.unsqueeze(1).repeat(1, self.size, 1) # (B, size, dim)\n","        # v_view: (B, dim, 1)\n","        v_view = self.v.unsqueeze(0).expand(self.batch_size, self.dim).unsqueeze(2)\n","        \n","        # (B, size, dim) * (B, dim, 1)\n","        u = torch.bmm(torch.tanh(q_ex + ref), v_view).squeeze(2)\n","        \n","        return u, ref\n","    \n","class LSTM(nn.Module):\n","    def __init__(self, n_hidden):\n","        super(LSTM, self).__init__()\n","        \n","        # parameters for input gate\n","        self.Wxi = nn.Linear(n_hidden, n_hidden)    # W(xt)\n","        self.Whi = nn.Linear(n_hidden, n_hidden)    # W(ht)\n","        self.wci = nn.Linear(n_hidden, n_hidden)    # w(ct)\n","        \n","        # parameters for forget gate\n","        self.Wxf = nn.Linear(n_hidden, n_hidden)    # W(xt)\n","        self.Whf = nn.Linear(n_hidden, n_hidden)    # W(ht)\n","        self.wcf = nn.Linear(n_hidden, n_hidden)    # w(ct)\n","        \n","        # parameters for cell gate\n","        self.Wxc = nn.Linear(n_hidden, n_hidden)    # W(xt)\n","        self.Whc = nn.Linear(n_hidden, n_hidden)    # W(ht)\n","        \n","        # parameters for forget gate\n","        self.Wxo = nn.Linear(n_hidden, n_hidden)    # W(xt)\n","        self.Who = nn.Linear(n_hidden, n_hidden)    # W(ht)\n","        self.wco = nn.Linear(n_hidden, n_hidden)    # w(ct)\n","    \n","    \n","    def forward(self, x, h, c):       # query and reference\n","        \n","        # input gate\n","        i = torch.sigmoid(self.Wxi(x) + self.Whi(h) + self.wci(c))\n","        # forget gate\n","        f = torch.sigmoid(self.Wxf(x) + self.Whf(h) + self.wcf(c))\n","        # cell gate\n","        c = f * c + i * torch.tanh(self.Wxc(x) + self.Whc(h))\n","        # output gate\n","        o = torch.sigmoid(self.Wxo(x) + self.Who(h) + self.wco(c))\n","        \n","        h = o * torch.tanh(c)\n","        \n","        return h, c\n","\n","class HPN(nn.Module):\n","    def __init__(self, n_feature, n_hidden):\n","\n","        super(HPN, self).__init__()\n","        self.city_size = 0\n","        self.batch_size = 0\n","        self.dim = n_hidden\n","        \n","        # lstm for first turn\n","        #self.lstm0 = nn.LSTM(n_hidden, n_hidden)\n","        \n","        # pointer layer\n","        self.pointer = Attention(n_hidden)\n","        self.TransPointer = Attention(n_hidden)\n","        \n","        # lstm encoder\n","        self.encoder = LSTM(n_hidden)\n","        \n","        # trainable first hidden input\n","        h0 = torch.FloatTensor(n_hidden)\n","        c0 = torch.FloatTensor(n_hidden)\n","        \n","        # trainable latent variable coefficient\n","        alpha = torch.ones(1)#####.cuda()\n","        \n","        self.h0 = nn.Parameter(h0)\n","        self.c0 = nn.Parameter(c0)\n","        \n","        self.alpha = nn.Parameter(alpha)\n","        self.h0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n","        self.c0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n","        \n","        r1 = torch.ones(1)\n","        r2 = torch.ones(1)\n","        r3 = torch.ones(1)\n","        self.r1 = nn.Parameter(r1)\n","        self.r2 = nn.Parameter(r2)\n","        self.r3 = nn.Parameter(r3)\n","        \n","        # embedding\n","        self.embedding_x = nn.Linear(n_feature, n_hidden)\n","        self.embedding_all = nn.Linear(n_feature, n_hidden)\n","        self.Transembedding_all = TransEncoderNet(6, 128, 8, 512, batchnorm=True)\n","        \n","        # vector to start decoding \n","        self.start_placeholder = nn.Parameter(torch.randn(n_hidden))\n","        \n","        # weights for GNN\n","        self.W1 = nn.Linear(n_hidden, n_hidden)\n","        self.W2 = nn.Linear(n_hidden, n_hidden)\n","        self.W3 = nn.Linear(n_hidden, n_hidden)\n","        \n","        # aggregation function for GNN\n","        self.agg_1 = nn.Linear(n_hidden, n_hidden)\n","        self.agg_2 = nn.Linear(n_hidden, n_hidden)\n","        self.agg_3 = nn.Linear(n_hidden, n_hidden)\n","        self.outagg = nn.Linear(2, 1)\n","    \n","    \n","    def forward(self,context,Transcontext, x, X_all, mask, h=None, c=None, latent=None):\n","        '''\n","        Inputs (B: batch size, size: city size, dim: hidden dimension)\n","        \n","        x: current city coordinate (B, 2)\n","        X_all: all cities' cooridnates (B, size, 2)\n","        mask: mask visited cities\n","        h: hidden variable (B, dim)\n","        c: cell gate (B, dim)\n","        latent: latent pointer vector from previous layer (B, size, dim)\n","        \n","        Outputs\n","        \n","        softmax: probability distribution of next city (B, size)\n","        h: hidden variable (B, dim)\n","        c: cell gate (B, dim)\n","        latent_u: latent pointer vector for next layer\n","        '''\n","        \n","        self.batch_size = X_all.size(0)\n","        self.city_size = X_all.size(1)\n","        \n","        # Check if this the first iteration loop\n","        if h is None or c is None:\n","            x          = self.start_placeholder    \n","            context = self.embedding_all(X_all)\n","            Transcontext,_ = self.Transembedding_all(context)\n","            \n","            # =============================\n","            # graph neural network encoder\n","            # =============================\n","\n","            # (B, size, dim)\n","            context = context.reshape(-1, self.dim)\n","            Transcontext = Transcontext.reshape(-1, self.dim)\n","\n","            context = self.r1 * self.W1(context)\\\n","                + (1-self.r1) * F.relu(self.agg_1(context/(self.city_size-1)))\n","\n","            context = self.r2 * self.W2(context)\\\n","                + (1-self.r2) * F.relu(self.agg_2(context/(self.city_size-1)))\n","\n","            context = self.r3 * self.W3(context)\\\n","                + (1-self.r3) * F.relu(self.agg_3(context/(self.city_size-1)))\n","            h0 = self.h0.unsqueeze(0).expand(self.batch_size, self.dim)\n","            c0 = self.c0.unsqueeze(0).expand(self.batch_size, self.dim)\n","\n","            h0 = h0.unsqueeze(0).contiguous()\n","            c0 = c0.unsqueeze(0).contiguous()\n","            \n","            # let h0, c0 be the hidden variable of first turn\n","            h = h0.squeeze(0)\n","            c = c0.squeeze(0)\n","        else:\n","            x          = self.embedding_x(x)\n","        # LSTM encoder\n","        h, c = self.encoder(x, h, c)\n","        # query vector\n","        q = h\n","        # pointer\n","        u1, _ = self.pointer(q, context)\n","        u2 ,_ = self.TransPointer(q,Transcontext)\n","        # Avg Agg between the two attention vectors\n","        u = (u1 + u2) / 2\n","        latent_u = u.clone()\n","        u = 10 * torch.tanh(u) + mask\n","        return context,Transcontext,F.softmax(u, dim=1), h, c, latent_u"]},{"cell_type":"markdown","metadata":{},"source":["# Main Training Cell"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-09-18T03:41:00.177227Z","iopub.status.busy":"2021-09-18T03:41:00.176955Z","iopub.status.idle":"2021-09-18T03:41:22.677365Z","shell.execute_reply":"2021-09-18T03:41:22.675301Z","shell.execute_reply.started":"2021-09-18T03:41:00.177192Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["=========================\n","prepare to train\n","=========================\n","Hyperparameters:\n","size 50\n","size_val 50\n","learning rate 0.0001\n","batch size 512\n","validation size 1000\n","steps 2500\n","epoch 100\n","=========================\n","epoch:0, batch:50/2500, reward:13.981800079345703\n","epoch:0, batch:100/2500, reward:12.78825855255127\n","epoch:0, batch:150/2500, reward:12.051730155944824\n","epoch:0, batch:200/2500, reward:11.33357048034668\n","epoch:0, batch:250/2500, reward:10.525376319885254\n","epoch:0, batch:300/2500, reward:10.245943069458008\n","epoch:0, batch:350/2500, reward:10.153414726257324\n","epoch:0, batch:400/2500, reward:10.28464126586914\n","epoch:0, batch:450/2500, reward:9.718462944030762\n","epoch:0, batch:500/2500, reward:9.994976043701172\n","epoch:0, batch:550/2500, reward:9.976591110229492\n","epoch:0, batch:600/2500, reward:9.69201374053955\n","epoch:0, batch:650/2500, reward:11.060633659362793\n","epoch:0, batch:700/2500, reward:11.292388916015625\n","epoch:0, batch:750/2500, reward:10.073175430297852\n","epoch:0, batch:800/2500, reward:9.679014205932617\n","epoch:0, batch:850/2500, reward:10.446287155151367\n","epoch:0, batch:900/2500, reward:9.619412422180176\n","epoch:0, batch:950/2500, reward:9.9529390335083\n","epoch:0, batch:1000/2500, reward:9.485227584838867\n","epoch:0, batch:1050/2500, reward:9.719277381896973\n","epoch:0, batch:1100/2500, reward:9.453798294067383\n","epoch:0, batch:1150/2500, reward:10.088136672973633\n","epoch:0, batch:1200/2500, reward:10.037810325622559\n","epoch:0, batch:1250/2500, reward:10.508085250854492\n","epoch:0, batch:1300/2500, reward:9.499747276306152\n","epoch:0, batch:1350/2500, reward:9.997331619262695\n","epoch:0, batch:1400/2500, reward:9.671065330505371\n","epoch:0, batch:1450/2500, reward:9.374791145324707\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-630a6898275a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlogprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/envs/GraphDTLP/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/envs/GraphDTLP/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["size = 50\n","TOL  =  1e-3\n","TINY =  1e-15\n","learn_rate = 1e-4    # learning rate\n","B = 512              # batch_size\n","B_val = 1000         # validation Batchsize\n","B_valLoop = 20       \n","size_val = 50       \n","steps = 2500        # training steps\n","n_epoch = 100       # epochs\n","\n","print('=========================')\n","print('prepare to train')\n","print('=========================')\n","print('Hyperparameters:')\n","print('size', size)\n","print('size_val', size_val)\n","print('learning rate', learn_rate)\n","print('batch size', B)\n","print('validation size', B_val)\n","print('steps', steps)\n","print('epoch', n_epoch)\n","print('=========================')\n","\n","###################\n","# Instantiate a training network and a baseline network\n","###################\n","\n","X_val = torch.rand(B_val,size_val,2).to(device)\n","\n","try: \n","    del Actor # remove existing model\n","    del Critic # remove existing model\n","except:\n","    pass\n","\n","Actor  = HPN(n_feature=2, n_hidden=128)\n","Critic = HPN(n_feature=2, n_hidden=128)\n","optimizer = optim.Adam(Actor.parameters(), lr=learn_rate)\n","\n","# Putting Critic model on the eval mode\n","Actor = Actor.to(device)\n","Critic = Critic.to(device)\n","Critic.eval()\n","\n","########################\n","# Remember to first initialize the model and optimizer, then load the dictionary locally.\n","#######################\n","epoch_ckpt = 0\n","tot_time_ckpt = 0\n","\n","val_mean = []\n","val_std  = []\n","\n","plot_performance_train = []\n","plot_performance_baseline = []\n","#********************************************# Uncomment these lines to re-start training with saved checkpoint #********************************************#\n","\"\"\"\n","checkpoint_file = \"./checkpoint/checkpoint_21-08-02--03-01-00-n50-gpu0.pkl\"\n","checkpoint = torch.load(checkpoint_file, map_location=device)\n","epoch_ckpt = checkpoint['epoch'] + 1\n","tot_time_ckpt = checkpoint['tot_time']\n","plot_performance_train = checkpoint['plot_performance_train']\n","plot_performance_baseline = checkpoint['plot_performance_baseline']\n","Critic.load_state_dict(checkpoint['model_baseline'])\n","Actor.load_state_dict(checkpoint['model_train'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","print('Re-start training with saved checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\n","del checkpoint\n","\"\"\"\n","#*********************************************# Uncomment these lines to re-start training with saved checkpoint #********************************************#\n","\n","\n","###################\n","#  Main training loop \n","#  The core training  concept mainly upon Sampling from the actor & taking the greedy action from the critic\n","###################\n","\n","start_training_time = time.time()\n","time_stamp = datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\")\n","\n","C = 0     # baseline\n","R = 0     # reward\n","\n","zero_to_bsz = torch.arange(B, device=device) # [0,1,...,bsz-1]\n","\n","for epoch in range(0,n_epoch):\n","    # re-start training with saved checkpoint\n","    epoch += epoch_ckpt\n","\n","    ###################\n","    # Train model for one epoch\n","    ###################\n","    \n","    start = time.time()\n","    Actor.train()\n","    \n","    for i in range(1,steps+1):\n","        \n","        X = torch.rand(B, size, 2)#.cuda()                \n","        mask = torch.zeros(B,size)#.cuda()\n","        R = 0\n","        logprobs = 0\n","        reward = 0\n","        Y = X.view(B,size,2)\n","        x = Y[:,0,:]\n","        h = None\n","        c = None\n","        context = None\n","        Transcontext = None \n","        \n","        #Actor Sampling phase\n","        for k in range(size):\n","            context,Transcontext,output, h, c, _ = Actor(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)            \n","            sampler = torch.distributions.Categorical(output)\n","            idx = sampler.sample()         \n","            Y1 = Y[zero_to_bsz, idx.data].clone()\n","            if k == 0:\n","                Y_ini = Y1.clone()\n","            if k > 0:\n","                reward = torch.sum((Y1 - Y0)**2 , dim=1 )**0.5\n","            Y0 = Y1.clone()  # --> insert current node into prev node for the next iteration\n","            x = Y[zero_to_bsz, idx.data].clone()\n","            R += reward\n","            logprobs += torch.log(output[zero_to_bsz, idx.data] + TINY)\n","            mask[zero_to_bsz, idx.data] += -np.inf    \n","        R += torch.sum((Y1 - Y_ini)**2 , dim=1 )**0.5\n","       \n","       \n","        # Critic Baseline phase\n","        mask = torch.zeros(B,size)#.cuda()\n","        C = 0\n","        baseline = 0\n","        Y = X.view(B,size,2)\n","        x = Y[:,0,:]\n","        h = None\n","        c = None\n","        context = None\n","        Transcontext = None\n","\n","        # compute tours for baseline without grad \"Cause we want to fix the weights for the critic\"\n","        with torch.no_grad():\n","            for k in range(size):\n","                context,Transcontext,output, h, c, _ = Critic(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n","                idx = torch.argmax(output, dim=1) # ----> greedy baseline critic\n","                Y1 = Y[zero_to_bsz, idx.data].clone()\n","                if k == 0:\n","                    Y_ini = Y1.clone()\n","                if k > 0:\n","                    baseline  = torch.sum((Y1 - Y0)**2 , dim=1 )**0.5\n","                Y0 = Y1.clone()\n","                x = Y[zero_to_bsz, idx.data].clone()\n","                C += baseline\n","                mask[zero_to_bsz, idx.data] += -np.inf\n","        C  += torch.sum((Y1 - Y_ini)**2 , dim=1 )**0.5\n","       \n","        ###################\n","        # Loss and backprop handling \n","        ###################\n","        \n","        loss = torch.mean((R - C) * logprobs)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if i % 50 == 0:\n","            print(\"epoch:{}, batch:{}/{}, reward:{}\".format(epoch, i, steps, R.mean().item()))\n","                \n","    time_one_epoch = time.time() - start\n","    time_tot = time.time() - start_training_time + tot_time_ckpt\n","    \n","    ###################\n","    # Evaluate train model and baseline \n","    # in this phase we just solve random instances with the actor and the critic\n","    # compare this soluation if we get any improvment we'll transfer the actor's\n","    # weights into the critic\n","    ###################\n","    \n","    # putting the actor in the eval mode\n","    Actor.eval()\n","    \n","    mean_tour_length_actor = 0\n","    mean_tour_length_critic = 0\n","\n","    for step in range(0,B_valLoop):\n","        \n","        # compute tour for model and baseline\n","        X = np.random.rand(B, size, 2)        \n","        X = torch.Tensor(X)#.cuda()\n","\n","        mask = torch.zeros(B,size)#.cuda()\n","        R = 0\n","        reward = 0\n","\n","        Y = X.view(B,size,2)\n","        x = Y[:,0,:]\n","        \n","        h = None\n","        c = None\n","        context = None\n","        Transcontext = None\n","\n","        with torch.no_grad():\n","            for k in range(size):\n","                \n","                context,Transcontext,output, h, c, _ = Actor(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)          \n","                idx = torch.argmax(output, dim=1)\n","\n","                Y1 = Y[zero_to_bsz, idx.data].clone()\n","                if k == 0:\n","                    Y_ini = Y1.clone()\n","                if k > 0:\n","                    #reward = torch.linalg.norm(Y1 - Y0, dim=1) # --> Calculation of the distance between two node\n","                    reward = torch.sum((Y1 - Y0)**2 , dim=1 )**0.5\n","\n","                Y0 = Y1.clone()  # --> insert current node into prev node for the next iteration\n","                x = Y[zero_to_bsz, idx.data].clone()\n","                R += reward\n","                mask[zero_to_bsz, idx.data] += -np.inf\n","                \n","        #R += torch.linalg.norm(Y1 - Y_ini, dim=1)\n","        R += torch.sum((Y1 - Y_ini)**2 , dim=1 )**0.5\n","\n","        \n","        # critic baseline\n","        mask = torch.zeros(B,size)#.cuda()\n","        C = 0\n","        baseline = 0\n","        \n","        Y = X.view(B,size,2)\n","        x = Y[:,0,:]\n","        \n","        h = None\n","        c = None\n","        context = None\n","        Transcontext = None\n","\n","        with torch.no_grad():\n","            for k in range(size):\n","                context,Transcontext,output, h, c, _ = Critic(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n","                idx = torch.argmax(output, dim=1)  \n","                Y1 = Y[zero_to_bsz, idx.data].clone()\n","                if k == 0:\n","                    Y_ini = Y1.clone()\n","                if k > 0:\n","                    #baseline = torch.linalg.norm(Y1-Y0, dim=1)\n","                    baseline  = torch.sum((Y1 - Y0)**2 , dim=1 )**0.5\n","                Y0 = Y1.clone()\n","                x = Y[zero_to_bsz, idx.data].clone()\n","                C += baseline\n","                mask[zero_to_bsz, idx.data] += -np.inf\n","                \n","        #C += torch.linalg.norm(Y1-Y_ini, dim=1) # ---> Last point to intial point\n","        C  += torch.sum((Y1 - Y_ini)**2 , dim=1 )**0.5\n","        \n","        mean_tour_length_actor  += R.mean().item()\n","        mean_tour_length_critic += C.mean().item()\n","        \n","    mean_tour_length_actor  =  mean_tour_length_actor  / B_valLoop\n","    mean_tour_length_critic =  mean_tour_length_critic / B_valLoop\n","\n","    # evaluate train model and baseline and update if train model is better\n","    update_baseline = mean_tour_length_actor + TOL < mean_tour_length_critic\n","    print('Avg Actor {} --- Avg Critic {}'.format(mean_tour_length_actor,mean_tour_length_critic))\n","    if update_baseline:\n","        Critic.load_state_dict(Actor.state_dict())\n","        print('My actor is going on the right road Hallelujah :) Updated')\n","        \n","    ###################\n","    # Valdiation train model and baseline on 1k random TSP instances\n","    ###################\n","    \n","    with torch.no_grad():\n","        # greedy validation\n","        tour_len = 0\n","        X = X_val\n","        mask = torch.zeros(B_val,size_val)#.cuda()\n","        R = 0\n","        reward = 0\n","\n","        Y = X.view(B_val, size_val, 2)    # to the same batch size\n","        x = Y[:,0,:]\n","        \n","        h = None\n","        c = None\n","        context = None\n","        Transcontext = None\n","\n","        for k in range(size_val):\n","\n","            context,Transcontext,output, h, c, _ = Critic(context,Transcontext,x=x, X_all=X, h=h, c=c, mask=mask)\n","            idx = torch.argmax(output, dim=1)\n","            Y1 = Y[[i for i in range(B_val)], idx.data]\n","            if k == 0:\n","                Y_ini = Y1.clone()\n","            if k > 0:\n","                #reward = torch.linalg.norm(Y1-Y0, dim=1)\n","                reward  = torch.sum((Y1 - Y0)**2 , dim=1 )**0.5\n","            Y0 = Y1.clone()\n","            x = Y[[i for i in range(B_val)], idx.data]\n","            R += reward\n","            mask[[i for i in range(B_val)], idx.data] += -np.inf\n","\n","        #R += torch.linalg.norm(Y1-Y_ini, dim=1)\n","        R  += torch.sum((Y1 - Y_ini)**2 , dim=1 )**0.5\n","        tour_len += R.mean().item()\n","        print('validation tour length:', tour_len)\n","\n","    # For checkpoint\n","    plot_performance_train.append([(epoch+1), mean_tour_length_actor])\n","    plot_performance_baseline.append([(epoch+1), mean_tour_length_critic])\n","    \n","    # Compute optimality gap\n","    if size==50: gap_train = mean_tour_length_actor/5.692- 1.0\n","    elif size==100: gap_train = mean_tour_length_actor/7.765- 1.0\n","    else: gap_train = -1.0\n","        \n","    # Print and save in txt file\n","    mystring_min = 'Epoch: {:d}, epoch time: {:.3f}min, tot time: {:.3f}day, L_actor: {:.3f}, L_critic: {:.3f}, gap_train(%): {:.3f}, update: {}'.format(\n","        epoch, time_one_epoch/60, time_tot/86400, mean_tour_length_actor, mean_tour_length_critic, 100 * gap_train, update_baseline)\n","    \n","    print(mystring_min)\n","    print('Save Checkpoints')\n","    \n","    # Saving checkpoint\n","    checkpoint_dir = os.path.join(\"checkpoint\")\n","    \n","    if not os.path.exists(checkpoint_dir):\n","        os.makedirs(checkpoint_dir)\n","        \n","    torch.save({\n","        'epoch': epoch,\n","        'time': time_one_epoch,\n","        'tot_time': time_tot,\n","        'loss': loss.item(),\n","        'plot_performance_train': plot_performance_train,\n","        'plot_performance_baseline': plot_performance_baseline,\n","        'mean_tour_length_val': tour_len,\n","        'model_baseline': Critic.state_dict(),\n","        'model_train': Actor.state_dict(),\n","        'optimizer': optimizer.state_dict(),\n","        }, '{}.pkl'.format(checkpoint_dir + \"/checkpoint_\" + time_stamp + \"-n{}\".format(size) + \"-gpu{}\".format(gpu_id)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}
